{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------Testing Accuracy on Validation Dataset---------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import unidecode\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.animation as animation\n",
    "import operator\n",
    "#import plotly.express as px\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day</td>\n",
       "      <td>['last', 'session', 'day']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit  precis    skyscrap...</td>\n",
       "      <td>['shanghai', 'also', 'realli', 'excit', 'preci...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho  quit company  ...</td>\n",
       "      <td>['recess', 'hit', 'veroniqu', 'branquinho', 'q...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>['happi', 'bday']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I like it</td>\n",
       "      <td>['I', 'like', 'it']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0                                  last session day    \n",
       "1           1  shanghai also realli excit  precis    skyscrap...   \n",
       "2           2  recess hit veroniqu branquinho  quit company  ...   \n",
       "3           3                                        happi bday    \n",
       "4           4                                        I like it     \n",
       "\n",
       "                                     Tweet_tokenized sentiment  \n",
       "0                         ['last', 'session', 'day']   neutral  \n",
       "1  ['shanghai', 'also', 'realli', 'excit', 'preci...   neutral  \n",
       "2  ['recess', 'hit', 'veroniqu', 'branquinho', 'q...   neutral  \n",
       "3                                  ['happi', 'bday']   neutral  \n",
       "4                                ['I', 'like', 'it']   neutral  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"logistic_regression.csv\")\n",
    "#data=data.drop('tokenized',axis=1)\n",
    "#data=data.drop('Unnamed: 0',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre - Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1020.322253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>883.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2649.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3533.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3534.000000\n",
       "mean   1766.500000\n",
       "std    1020.322253\n",
       "min       0.000000\n",
       "25%     883.250000\n",
       "50%    1766.500000\n",
       "75%    2649.750000\n",
       "max    3533.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     last session day\n",
       "1    shanghai also realli excit precis skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                           happi bday\n",
       "4                                            i like it\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lower case\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwards Removal\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([word for word in str(x).split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     last session day\n",
       "1    shanghai also really exit precise skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                            happy day\n",
       "4                                                 like\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('http://[A-Za-z0-9./]+','',tweet) \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    return tweet\n",
    "data['text'] = data['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day httptwitpiccomezh</td>\n",
       "      <td>negative</td>\n",
       "      <td>[last, session, day, httptwitpiccomezh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit precis skyscrap gal...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[shanghai, also, realli, excit, precis, skyscr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho quit company shame</td>\n",
       "      <td>positive</td>\n",
       "      <td>[recess, hit, veroniqu, branquinho, quit, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[happi, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>httptwitpiccomwp like</td>\n",
       "      <td>positive</td>\n",
       "      <td>[httptwitpiccomwp, like]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment  \\\n",
       "0           0                 last session day httptwitpiccomezh  negative   \n",
       "1           1  shanghai also realli excit precis skyscrap gal...   neutral   \n",
       "2           2  recess hit veroniqu branquinho quit company shame  positive   \n",
       "3           3                                         happi bday   neutral   \n",
       "4           4                              httptwitpiccomwp like  positive   \n",
       "\n",
       "                                           tokenized  \n",
       "0            [last, session, day, httptwitpiccomezh]  \n",
       "1  [shanghai, also, realli, excit, precis, skyscr...  \n",
       "2  [recess, hit, veroniqu, branquinho, quit, comp...  \n",
       "3                                      [happi, bday]  \n",
       "4                           [httptwitpiccomwp, like]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "data['tokenized'] = data['text'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction using TF-IDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "cv = TfidfVectorizer(max_features=5000) \n",
    "x = cv.fit_transform(data['text'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "3529    1.0\n",
      "3530    0.0\n",
      "3531    0.0\n",
      "3532    0.0\n",
      "3533    0.0\n",
      "Name: sentiment, Length: 3534, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.sentiment[data.sentiment == 'positive'] = 1\n",
    "data.sentiment[data.sentiment == 'neutral'] = 0\n",
    "data.sentiment[data.sentiment == 'negative'] = 2\n",
    "y=data['sentiment'].astype('float')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon,uniform,randint\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,cross_val_predict,validation_curve\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0) #Basic train_test_split works here\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91       710\n",
      "         1.0       0.88      0.30      0.45        69\n",
      "         2.0       0.72      0.17      0.28       105\n",
      "\n",
      "    accuracy                           0.84       884\n",
      "   macro avg       0.81      0.49      0.55       884\n",
      "weighted avg       0.83      0.84      0.80       884\n",
      "\n",
      "Accuracy : 0.8371040723981901 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, n_jobs=-1)\n",
    "m.fit(x_train, y_train)\n",
    "predictions = m.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy :\",accuracy_score(y_test, predictions),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099547511312217\n",
      "[[709   0   1]\n",
      " [ 66   1   2]\n",
      " [ 99   0   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      1.00      0.90       710\n",
      "         1.0       1.00      0.01      0.03        69\n",
      "         2.0       0.67      0.06      0.11       105\n",
      "\n",
      "    accuracy                           0.81       884\n",
      "   macro avg       0.83      0.36      0.34       884\n",
      "weighted avg       0.81      0.81      0.73       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With single train test split\n",
    "clf = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031674208144797\n",
      "[[710   0   0]\n",
      " [ 69   0   0]\n",
      " [105   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       710\n",
      "         1.0       0.00      0.00      0.00        69\n",
      "         2.0       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.80       884\n",
      "   macro avg       0.27      0.33      0.30       884\n",
      "weighted avg       0.65      0.80      0.72       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multinomial NB with single train test split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1   Shanghai is also really exciting (precisely -...  positive\n",
       "2  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3                                        happy bday!  positive\n",
       "4             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534</td>\n",
       "      <td>3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3530</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text sentiment\n",
       "count     3534      3534\n",
       "unique    3530         3\n",
       "top     #NAME?   neutral\n",
       "freq         5      1430"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     last session of the day http://twitpic.com/67ezh\n",
       "1    shanghai is also really exciting (precisely --...\n",
       "2    recession hit veronique branquinho, she has to...\n",
       "3                                          happy bday!\n",
       "4               http://twitpic.com/4w75p - i like it!!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lower case\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwards Removal\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([word for word in str(x).split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            last session day http://twitpic.com/67ezh\n",
       "1    shanghai also really exciting (precisely -- sk...\n",
       "2    recession hit veronique branquinho, quit compa...\n",
       "3                                           happy day!\n",
       "4                 http://twitpic.com/4w75p - like it!!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('http://[A-Za-z0-9./]+','',tweet) \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    return tweet\n",
    "data['text'] = data['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, also, really, exciting, precisely, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[recession, hit, veronique, branquinho, quit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>[happy, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>[like, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0                                  last session day    neutral   \n",
       "1  shanghai also really exciting precisely  skysc...  positive   \n",
       "2  recession hit veronique branquinho quit compan...  negative   \n",
       "3                                         happy bday  positive   \n",
       "4                                            like it  positive   \n",
       "\n",
       "                                           tokenized  \n",
       "0                               [last, session, day]  \n",
       "1  [shanghai, also, really, exciting, precisely, ...  \n",
       "2  [recession, hit, veronique, branquinho, quit, ...  \n",
       "3                                      [happy, bday]  \n",
       "4                                         [like, it]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "data['tokenized'] = data['text'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "cv = TfidfVectorizer(max_features=5000) \n",
    "x = cv.fit_transform(data['text'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       1.0\n",
      "2       2.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "3529    2.0\n",
      "3530    1.0\n",
      "3531    2.0\n",
      "3532    1.0\n",
      "3533    1.0\n",
      "Name: sentiment, Length: 3534, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.sentiment[data.sentiment == 'positive'] = 1\n",
    "data.sentiment[data.sentiment == 'neutral'] = 0\n",
    "data.sentiment[data.sentiment == 'negative'] = 2\n",
    "y=data['sentiment'].astype('float')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon,uniform,randint\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,cross_val_predict,validation_curve\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0) #Basic train_test_split works here\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.75      0.64       355\n",
      "         1.0       0.73      0.64      0.69       273\n",
      "         2.0       0.68      0.43      0.52       256\n",
      "\n",
      "    accuracy                           0.62       884\n",
      "   macro avg       0.66      0.61      0.62       884\n",
      "weighted avg       0.65      0.62      0.62       884\n",
      "\n",
      "Accuracy : 0.6244343891402715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, n_jobs=-1)\n",
    "m.fit(x_train, y_train)\n",
    "predictions = m.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy :\",accuracy_score(y_test, predictions),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357466063348416\n",
      "[[286  35  34]\n",
      " [103 165   5]\n",
      " [128  17 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.81      0.66       355\n",
      "         1.0       0.76      0.60      0.67       273\n",
      "         2.0       0.74      0.43      0.55       256\n",
      "\n",
      "    accuracy                           0.64       884\n",
      "   macro avg       0.68      0.61      0.63       884\n",
      "weighted avg       0.67      0.64      0.63       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With single train test split\n",
    "clf = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5984162895927602\n",
      "[[289  37  29]\n",
      " [112 159   2]\n",
      " [165  10  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.81      0.63       355\n",
      "         1.0       0.77      0.58      0.66       273\n",
      "         2.0       0.72      0.32      0.44       256\n",
      "\n",
      "    accuracy                           0.60       884\n",
      "   macro avg       0.67      0.57      0.58       884\n",
      "weighted avg       0.65      0.60      0.58       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multinomial NB with single train test split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2650,) (884,) (2650,) (884,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "text = data['text'].values\n",
    "labels = data['sentiment'].values\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, labels)\n",
    "print(text_train.shape, text_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "maxlen = 500\n",
    "embedding_size = 32\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_train)\n",
    "x_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 19:41:52.863784  6052 deprecation.py:506] From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0622 19:41:52.902654  6052 deprecation.py:506] From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           640000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 722,561\n",
      "Trainable params: 722,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\n",
    "model.add(LSTM(128))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(1, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        min_delta=1e-4,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='weights.h5',\n",
    "        monitor='val_accuracy', \n",
    "        mode='max', \n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2650 samples, validate on 884 samples\n",
      "Epoch 1/2\n",
      "2640/2650 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.3064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 19:46:50.421300  6052 callbacks.py:1259] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "W0622 19:46:50.421300  6052 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 35s 13ms/sample - loss: 0.3877 - acc: 0.3068 - val_loss: 0.2818 - val_acc: 0.3281\n",
      "Epoch 2/2\n",
      "2640/2650 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.3095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 19:47:21.650425  6052 callbacks.py:1259] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "W0622 19:47:21.650425  6052 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2650/2650 [==============================] - 31s 12ms/sample - loss: 0.1732 - acc: 0.3091 - val_loss: 0.2142 - val_acc: 0.3247\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=60, validation_data=(x_test, y_test), epochs=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

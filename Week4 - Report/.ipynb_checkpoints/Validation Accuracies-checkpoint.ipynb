{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import unidecode\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.animation as animation\n",
    "import operator\n",
    "#import plotly.express as px\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day httptwitpiccomezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit precis  skyscrap ga...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho quit company shame</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>httptwitpiccomwp  like it</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment\n",
       "0           0                 last session day httptwitpiccomezh   neutral\n",
       "1           1  shanghai also realli excit precis  skyscrap ga...  positive\n",
       "2           2  recess hit veroniqu branquinho quit company shame   neutral\n",
       "3           3                                         happi bday   neutral\n",
       "4           4                          httptwitpiccomwp  like it   neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"validation2.csv\")\n",
    "#data=data.drop('tokenized',axis=1)\n",
    "#data=data.drop('Unnamed: 0',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1020.322253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>883.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1766.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2649.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3533.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3534.000000\n",
       "mean   1766.500000\n",
       "std    1020.322253\n",
       "min       0.000000\n",
       "25%     883.250000\n",
       "50%    1766.500000\n",
       "75%    2649.750000\n",
       "max    3533.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   last session day httptwitpiccomezh\n",
       "1    shanghai also realli excit precis skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                           happi bday\n",
       "4                             httptwitpiccomwp like it\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lower case\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwards Removal\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([word for word in str(x).split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   last session day httptwitpiccomezh\n",
       "1    shanghai also really exit precise skyscrap gal...\n",
       "2    recess hit veroniqu branquinho quit company shame\n",
       "3                                            happy day\n",
       "4                                httptwitpiccomwp like\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    return tweet\n",
    "data['text'] = data['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>last session day httptwitpiccomezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, day, httptwitpiccomezh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shanghai also realli excit precis skyscrap gal...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, also, realli, excit, precis, skyscr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>recess hit veroniqu branquinho quit company shame</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[recess, hit, veroniqu, branquinho, quit, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happi bday</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[happi, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>httptwitpiccomwp like</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[httptwitpiccomwp, like]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment  \\\n",
       "0           0                 last session day httptwitpiccomezh   neutral   \n",
       "1           1  shanghai also realli excit precis skyscrap gal...  positive   \n",
       "2           2  recess hit veroniqu branquinho quit company shame   neutral   \n",
       "3           3                                         happi bday   neutral   \n",
       "4           4                              httptwitpiccomwp like   neutral   \n",
       "\n",
       "                                           tokenized  \n",
       "0            [last, session, day, httptwitpiccomezh]  \n",
       "1  [shanghai, also, realli, excit, precis, skyscr...  \n",
       "2  [recess, hit, veroniqu, branquinho, quit, comp...  \n",
       "3                                      [happi, bday]  \n",
       "4                           [httptwitpiccomwp, like]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "data['tokenized'] = data['text'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "cv = TfidfVectorizer(max_features=5000) \n",
    "x = cv.fit_transform(data['text'].tolist()).toarray()\n",
    "#y=pd.get_dummies(df['sentiment'])\n",
    "#y=y.iloc[:,1].values\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, data['sentiment'], test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       1.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "3529    2.0\n",
      "3530    0.0\n",
      "3531    2.0\n",
      "3532    1.0\n",
      "3533    1.0\n",
      "Name: sentiment, Length: 3534, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.sentiment[data.sentiment == 'positive'] = 1\n",
    "data.sentiment[data.sentiment == 'neutral'] = 0\n",
    "data.sentiment[data.sentiment == 'negative'] = 2\n",
    "y=data['sentiment'].astype('float')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon,uniform,randint\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,cross_val_predict,validation_curve\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0) #Basic train_test_split works here\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.72      0.69      2774\n",
      "         1.0       0.75      0.76      0.75      2155\n",
      "         2.0       0.72      0.59      0.65      1933\n",
      "\n",
      "    accuracy                           0.70      6862\n",
      "   macro avg       0.71      0.69      0.70      6862\n",
      "weighted avg       0.70      0.70      0.70      6862\n",
      "\n",
      "Accuracy : 0.6981929466627805 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, n_jobs=-1)\n",
    "m.fit(x_train, y_train)\n",
    "predictions = m.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "#print(\"Accuracy :\",accuracy_score(y_test, predictions),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6926552025648499\n",
      "[[2122  330  322]\n",
      " [ 560 1502   93]\n",
      " [ 704  100 1129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.76      0.69      2774\n",
      "         1.0       0.78      0.70      0.74      2155\n",
      "         2.0       0.73      0.58      0.65      1933\n",
      "\n",
      "    accuracy                           0.69      6862\n",
      "   macro avg       0.71      0.68      0.69      6862\n",
      "weighted avg       0.70      0.69      0.69      6862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With single train test split\n",
    "clf = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394637132031478\n",
      "[[2144  356  274]\n",
      " [ 784 1294   77]\n",
      " [ 878  105  950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.77      0.65      2774\n",
      "         1.0       0.74      0.60      0.66      2155\n",
      "         2.0       0.73      0.49      0.59      1933\n",
      "\n",
      "    accuracy                           0.64      6862\n",
      "   macro avg       0.68      0.62      0.63      6862\n",
      "weighted avg       0.66      0.64      0.64      6862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multinomial NB with single train test split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

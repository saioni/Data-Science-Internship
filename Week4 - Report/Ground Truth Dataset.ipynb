{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------Testing on Ground Truth Dataset------------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import unidecode\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.animation as animation\n",
    "import operator\n",
    "#import plotly.express as px\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1   Shanghai is also really exciting (precisely -...  positive\n",
       "2  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3                                        happy bday!  positive\n",
       "4             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3534</td>\n",
       "      <td>3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3530</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text sentiment\n",
       "count     3534      3534\n",
       "unique    3530         3\n",
       "top     #NAME?   neutral\n",
       "freq         5      1430"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     last session of the day http://twitpic.com/67ezh\n",
       "1    shanghai is also really exciting (precisely --...\n",
       "2    recession hit veronique branquinho, she has to...\n",
       "3                                          happy bday!\n",
       "4               http://twitpic.com/4w75p - i like it!!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lower case\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stopwards Removal\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([word for word in str(x).split() if not word in set(stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            last session day http://twitpic.com/67ezh\n",
       "1    shanghai also really exciting (precisely -- sk...\n",
       "2    recession hit veronique branquinho, quit compa...\n",
       "3                                           happy day!\n",
       "4                 http://twitpic.com/4w75p - like it!!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('http://[A-Za-z0-9./]+','',tweet) \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    return tweet\n",
    "data['text'] = data['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai also really exciting precisely  skysc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, also, really, exciting, precisely, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[recession, hit, veronique, branquinho, quit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>[happy, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>[like, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0                                  last session day    neutral   \n",
       "1  shanghai also really exciting precisely  skysc...  positive   \n",
       "2  recession hit veronique branquinho quit compan...  negative   \n",
       "3                                         happy bday  positive   \n",
       "4                                            like it  positive   \n",
       "\n",
       "                                           tokenized  \n",
       "0                               [last, session, day]  \n",
       "1  [shanghai, also, really, exciting, precisely, ...  \n",
       "2  [recession, hit, veronique, branquinho, quit, ...  \n",
       "3                                      [happy, bday]  \n",
       "4                                         [like, it]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "data['tokenized'] = data['text'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "cv = TfidfVectorizer(max_features=5000) \n",
    "x = cv.fit_transform(data['text'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       1.0\n",
      "2       2.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "3529    2.0\n",
      "3530    1.0\n",
      "3531    2.0\n",
      "3532    1.0\n",
      "3533    1.0\n",
      "Name: sentiment, Length: 3534, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.sentiment[data.sentiment == 'positive'] = 1\n",
    "data.sentiment[data.sentiment == 'neutral'] = 0\n",
    "data.sentiment[data.sentiment == 'negative'] = 2\n",
    "y=data['sentiment'].astype('float')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon,uniform,randint\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,cross_val_predict,validation_curve\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0) #Basic train_test_split works here\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.75      0.64       355\n",
      "         1.0       0.73      0.64      0.68       273\n",
      "         2.0       0.68      0.43      0.53       256\n",
      "\n",
      "    accuracy                           0.62       884\n",
      "   macro avg       0.66      0.61      0.62       884\n",
      "weighted avg       0.65      0.62      0.62       884\n",
      "\n",
      "Accuracy : 0.6244343891402715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, n_jobs=-1)\n",
    "m.fit(x_train, y_train)\n",
    "predictions = m.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Accuracy :\",accuracy_score(y_test, predictions),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357466063348416\n",
      "[[286  35  34]\n",
      " [103 165   5]\n",
      " [128  17 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.81      0.66       355\n",
      "         1.0       0.76      0.60      0.67       273\n",
      "         2.0       0.74      0.43      0.55       256\n",
      "\n",
      "    accuracy                           0.64       884\n",
      "   macro avg       0.68      0.61      0.63       884\n",
      "weighted avg       0.67      0.64      0.63       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With single train test split\n",
    "clf = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5984162895927602\n",
      "[[289  37  29]\n",
      " [112 159   2]\n",
      " [165  10  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.81      0.63       355\n",
      "         1.0       0.77      0.58      0.66       273\n",
      "         2.0       0.72      0.32      0.44       256\n",
      "\n",
      "    accuracy                           0.60       884\n",
      "   macro avg       0.67      0.57      0.58       884\n",
      "weighted avg       0.65      0.60      0.58       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multinomial NB with single train test split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      " 0.6278280542986425\n",
      "\n",
      "\n",
      "COnfusion Matrix\n",
      " [[261  43  51]\n",
      " [ 87 176  10]\n",
      " [120  18 118]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.74      0.63       355\n",
      "         1.0       0.74      0.64      0.69       273\n",
      "         2.0       0.66      0.46      0.54       256\n",
      "\n",
      "    accuracy                           0.63       884\n",
      "   macro avg       0.65      0.61      0.62       884\n",
      "weighted avg       0.64      0.63      0.62       884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier().fit(x_train, y_train)\n",
    "\n",
    "y_pred=xgb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nConfusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
